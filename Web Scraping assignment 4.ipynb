{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed1062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# 1. Most Viewed Videos on YouTube\n",
    "def scrape_youtube_videos():\n",
    "    url = 'https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    table = soup.find('table', {'class': 'wikitable sortable'})\n",
    "\n",
    "    videos = []\n",
    "    for row in table.find_all('tr')[1:]:\n",
    "        cols = row.find_all('td')\n",
    "        if len(cols) > 4:\n",
    "            video = {\n",
    "                'Rank': cols[0].text.strip(),\n",
    "                'Name': cols[1].text.strip(),\n",
    "                'Artist': cols[2].text.strip(),\n",
    "                'Upload date': cols[3].text.strip(),\n",
    "                'Views': cols[4].text.strip()\n",
    "            }\n",
    "            videos.append(video)\n",
    "    return videos\n",
    "\n",
    "# 2. Team Indiaâ€™s International Fixtures\n",
    "def scrape_bcci_fixtures():\n",
    "    options = Options()\n",
    "    options.headless = True\n",
    "    service = Service(executable_path='/path/to/chromedriver')  # Replace with the actual path to chromedriver\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "    url = 'https://www.bcci.tv/'\n",
    "    driver.get(url)\n",
    "    driver.find_element(By.LINK_TEXT, 'Fixtures').click()\n",
    "\n",
    "    fixtures = []\n",
    "    rows = driver.find_elements(By.CSS_SELECTOR, 'div.fixture')\n",
    "    for row in rows:\n",
    "        series = row.find_element(By.CSS_SELECTOR, 'div.series-name').text.strip()\n",
    "        place = row.find_element(By.CSS_SELECTOR, 'div.place').text.strip()\n",
    "        date = row.find_element(By.CSS_SELECTOR, 'div.date').text.strip()\n",
    "        time = row.find_element(By.CSS_SELECTOR, 'div.time').text.strip()\n",
    "        fixtures.append({'Series': series, 'Place': place, 'Date': date, 'Time': time})\n",
    "\n",
    "    driver.quit()\n",
    "    return fixtures\n",
    "\n",
    "# 3. State-wise GDP of India\n",
    "def scrape_state_gdp():\n",
    "    url = 'http://statisticstimes.com/'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    economy_link = soup.find('a', text='Economy').get('href')\n",
    "    response = requests.get(economy_link)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    table = soup.find('table', {'id': 'table_id'})\n",
    "    data = []\n",
    "    for row in table.find_all('tr')[1:]:\n",
    "        cols = row.find_all('td')\n",
    "        if len(cols) >= 6:\n",
    "            item = {\n",
    "                'Rank': cols[0].text.strip(),\n",
    "                'State': cols[1].text.strip(),\n",
    "                'GSDP (18-19)': cols[2].text.strip(),\n",
    "                'GSDP (19-20)': cols[3].text.strip(),\n",
    "                'Share (18-19)': cols[4].text.strip(),\n",
    "                'GDP ($ billion)': cols[5].text.strip()\n",
    "            }\n",
    "            data.append(item)\n",
    "    return data\n",
    "\n",
    "# 4. Trending Repositories on GitHub\n",
    "def scrape_github_trending():\n",
    "    options = Options()\n",
    "    options.headless = True\n",
    "    service = Service(executable_path='/path/to/chromedriver')  # Replace with the actual path to chromedriver\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "    url = 'https://github.com/'\n",
    "    driver.get(url)\n",
    "    driver.find_element(By.LINK_TEXT, 'Explore').click()\n",
    "    driver.find_element(By.LINK_TEXT, 'Trending').click()\n",
    "\n",
    "    repos = []\n",
    "    repo_elements = driver.find_elements(By.CSS_SELECTOR, 'article.Box-row')\n",
    "    for repo in repo_elements:\n",
    "        title = repo.find_element(By.CSS_SELECTOR, 'h1').text.strip()\n",
    "        description = repo.find_element(By.CSS_SELECTOR, 'p').text.strip()\n",
    "        contributors = repo.find_element(By.CSS_SELECTOR, 'a').text.strip()\n",
    "        language = repo.find_element(By.CSS_SELECTOR, 'span[itemprop=\"programmingLanguage\"]').text.strip()\n",
    "        repos.append({'Title': title, 'Description': description, 'Contributors': contributors, 'Language': language})\n",
    "\n",
    "    driver.quit()\n",
    "    return repos\n",
    "\n",
    "# 5. Top 100 Songs on Billboard\n",
    "def scrape_billboard_hot_100():\n",
    "    url = 'https://www.billboard.com/charts/hot-100/'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    songs = []\n",
    "    rows = soup.find_all('div', {'class': 'o-chart-results-list-row-container'})\n",
    "    for row in rows:\n",
    "        song = {\n",
    "            'Song Name': row.find('span', {'class': 'o-chart-results-list-row-title'}).text.strip(),\n",
    "            'Artist': row.find('span', {'class': 'o-chart-results-list-row-artist'}).text.strip(),\n",
    "            'Last Week Rank': row.find('span', {'class': 'c-label'}).text.strip(),\n",
    "            'Peak Rank': row.find('span', {'class': 'c-label'}).text.strip(),\n",
    "            'Weeks on Board': row.find('span', {'class': 'c-label'}).text.strip()\n",
    "        }\n",
    "        songs.append(song)\n",
    "    return songs\n",
    "\n",
    "# 6. Highest Selling Novels\n",
    "def scrape_highest_selling_novels():\n",
    "    url = 'https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    books = []\n",
    "    table = soup.find('table', {'class': 'wikitable'})\n",
    "    for row in table.find_all('tr')[1:]:\n",
    "        cols = row.find_all('td')\n",
    "        if len(cols) >= 5:\n",
    "            book = {\n",
    "                'Book Name': cols[0].text.strip(),\n",
    "                'Author': cols[1].text.strip(),\n",
    "                'Volumes Sold': cols[2].text.strip(),\n",
    "                'Publisher': cols[3].text.strip(),\n",
    "                'Genre': cols[4].text.strip()\n",
    "            }\n",
    "            books.append(book)\n",
    "    return books\n",
    "\n",
    "# 7. Most Watched TV Series of All Time\n",
    "def scrape_imdb_tv_series():\n",
    "    url = 'https://www.imdb.com/list/ls095964455/'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    series = []\n",
    "    items = soup.find_all('div', {'class': 'lister-item-content'})\n",
    "    for item in items:\n",
    "        series_details = {\n",
    "            'Name': item.find('h3', {'class': 'lister-item-header'}).find('a').text.strip(),\n",
    "            'Year Span': item.find('span', {'class': 'lister-item-year'}).text.strip(),\n",
    "            'Genre': item.find('span', {'class': 'genre'}).text.strip(),\n",
    "            'Run Time': item.find('span', {'class': 'runtime'}).text.strip(),\n",
    "            'Rating': item.find('span', {'class': 'ipl-rating-star__rating'}).text.strip(),\n",
    "            'Votes': item.find('span', {'class': 'lister-item-year'}).find_next('span').text.strip()\n",
    "        }\n",
    "        series.append(series_details)\n",
    "    return series\n",
    "\n",
    "# 8. Datasets from UCI Machine Learning Repository\n",
    "def scrape_uci_datasets():\n",
    "    url = 'https://archive.ics.uci.edu/ml/index.php'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    datasets = []\n",
    "    rows = soup.find_all('tr', {'class': 'odd'})\n",
    "    for row in rows:\n",
    "        dataset = {\n",
    "            'Dataset Name': row.find('td', {'class': 'name'}).text.strip()\n",
    "            # Additional details can be scraped similarly\n",
    "        }\n",
    "        datasets.append(dataset)\n",
    "    return datasets\n",
    "\n",
    "# Run the functions to scrape the data\n",
    "youtube_videos = scrape_youtube_videos()\n",
    "bcci_fixtures = scrape_bcci_fixtures()\n",
    "state_gdp = scrape_state_gdp()\n",
    "github_trending = scrape_github_trending()\n",
    "billboard_hot_100 = scrape_billboard_hot_100()\n",
    "highest_selling_novels = scrape_highest_selling_novels()\n",
    "imdb_tv_series = scrape_imdb_tv_series()\n",
    "uci_datasets = scrape_uci_datasets()\n",
    "\n",
    "# Output the results (for example purposes, this can be adjusted as needed)\n",
    "print(youtube_videos)\n",
    "print(bcci_fixtures)\n",
    "print(state_gdp)\n",
    "print(github_trending)\n",
    "print(billboard_hot_100)\n",
    "print(highest_selling_novels)\n",
    "print(imdb_tv_series)\n",
    "print(uci_datasets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
